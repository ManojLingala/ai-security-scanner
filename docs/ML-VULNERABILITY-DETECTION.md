# ML-Based Vulnerability Detection System

This document explains how to use the machine learning-based vulnerability detection system integrated into the AI Security Scanner.

## Overview

The ML vulnerability detection system provides advanced security analysis capabilities using a combination of:

1. **Pattern-based detection** - Fast regex patterns for known vulnerability types
2. **Contextual analysis** - ML-enhanced confidence scoring based on code context
3. **Ensemble methods** - Combining multiple detection approaches for higher accuracy
4. **External API integration** - Optional integration with commercial security APIs

## Architecture

### Components

- **MLVulnerabilityProvider**: Core ML-based vulnerability detector
- **HybridMLVulnerabilityProvider**: Ensemble detector combining local ML with external APIs
- **MLVulnerabilityDetector**: Engine containing vulnerability patterns and ML logic

### Supported Vulnerability Types

| CWE ID | Vulnerability Type | Severity | Detection Method |
|--------|-------------------|----------|------------------|
| CWE-89 | SQL Injection | Critical | Pattern + Context |
| CWE-79 | Cross-Site Scripting (XSS) | High | Pattern + Context |
| CWE-78 | Command Injection | Critical | Pattern + Context |
| CWE-22 | Path Traversal | High | Pattern + Context |
| CWE-798 | Hardcoded Credentials | Critical | Pattern + Entropy |
| CWE-502 | Insecure Deserialization | High | Pattern + Context |
| GEN-001 | AI-Generated Patterns | Low | Pattern + NLP |

## Configuration

### Basic Configuration

Add to `appsettings.json`:

```json
{
  "AIProviders": {
    "MLVulnerabilityDetector": {
      "Enabled": true,
      "CostPerRequest": 0.001,
      "MaxCodeLength": 100000,
      "ConfidenceThreshold": 0.3
    },
    "HybridML": {
      "Enabled": true,
      "UseLocalML": true,
      "UseExternalAPIs": false,
      "CostPerRequest": 0.05
    }
  }
}
```

### External API Integration

For enhanced detection with commercial APIs:

```json
{
  "AIProviders": {
    "CodeGuru": {
      "ApiKey": "your-amazon-codeguru-key",
      "ApiEndpoint": "https://codeguru-reviewer.amazonaws.com",
      "Enabled": true
    },
    "Snyk": {
      "ApiKey": "your-snyk-api-key", 
      "ApiEndpoint": "https://snyk.io/api/v1",
      "Enabled": true
    }
  }
}
```

## Usage Examples

### Basic Code Analysis

```csharp
// Initialize the ML provider
var mlProvider = serviceProvider.GetService<MLVulnerabilityProvider>();

// Analyze code
var code = @"
    string sql = ""SELECT * FROM users WHERE id = "" + userId;
    SqlCommand cmd = new SqlCommand(sql, connection);
";

var context = new AIAnalysisContext
{
    Language = "csharp",
    OrganizationId = organizationId,
    IncludeAIDetection = true
};

var result = await mlProvider.AnalyzeCodeAsync(code, context);

// Process results
foreach (var vulnerability in result.DetectedVulnerabilities)
{
    Console.WriteLine($"{vulnerability.Type} - Line {vulnerability.LineNumber}");
    Console.WriteLine($"Severity: {vulnerability.Severity}");
    Console.WriteLine($"Confidence: {vulnerability.Confidence:P}");
    Console.WriteLine($"Recommendation: {vulnerability.Recommendation}");
}
```

### Hybrid Analysis with Multiple Providers

```csharp
// Use hybrid provider for enhanced detection
var hybridProvider = serviceProvider.GetService<HybridMLVulnerabilityProvider>();

var result = await hybridProvider.AnalyzeCodeAsync(code, context);

// Get ensemble results with higher confidence
Console.WriteLine($"Analyzed with: {result.MLModelUsed}");
Console.WriteLine($"Overall confidence: {result.ConfidenceScore:P}");
Console.WriteLine($"Analysis metadata:");

foreach (var metadata in result.AnalysisMetadata)
{
    Console.WriteLine($"  {metadata.Key}: {metadata.Value}");
}
```

### Package Validation

```csharp
var suspiciousPackages = new List<string>
{
    "test-package-123",
    "ai-generated-lib",
    "demo-module-temp"
};

var packageResult = await hybridProvider.ValidatePackagesAsync(
    suspiciousPackages, 
    "npm");

foreach (var package in packageResult.VulnerablePackages)
{
    if (package.HasVulnerabilities)
    {
        Console.WriteLine($"Suspicious package: {package.PackageName}");
        foreach (var vuln in package.Vulnerabilities)
        {
            Console.WriteLine($"  - {vuln.Description} ({vuln.Confidence:P})");
        }
    }
}
```

## Detection Features

### Contextual Confidence Scoring

The ML system adjusts confidence based on context:

- **Comments**: Vulnerabilities in comments get very low confidence (×0.1)
- **String literals**: Reduced confidence for patterns in strings (×0.7)
- **Validation nearby**: Lower confidence if validation code is detected (×0.5)

### Ensemble Scoring

When using the hybrid provider:

- Multiple detectors run in parallel
- Results are merged and deduplicated
- Confidence boosted for vulnerabilities detected by multiple providers
- Final confidence calculated using weighted average

### Performance Characteristics

| Code Size | Analysis Time | Memory Usage |
|-----------|---------------|--------------|
| 100 lines | ~50ms | ~2MB |
| 1,000 lines | ~200ms | ~5MB |
| 10,000 lines | ~1.5s | ~20MB |
| 100,000 lines | ~15s | ~100MB |

## API Integration

### REST API Usage

```bash
# Analyze code via API
curl -X POST "https://localhost:7001/api/scans/start" \
  -H "Authorization: Bearer YOUR_JWT_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "repositoryId": "repository-guid",
    "aiProviders": ["ML-VulnerabilityDetector"],
    "includeAIDetection": true
  }'
```

### Real-time Results via SignalR

```javascript
// Connect to scan progress hub
const connection = new signalR.HubConnectionBuilder()
    .withUrl("/hubs/scanprogress", {
        accessTokenFactory: () => yourJwtToken
    })
    .build();

// Listen for ML detection results
connection.on("VulnerabilityDetected", (vulnerability) => {
    console.log(`ML detected: ${vulnerability.type}`);
    console.log(`Confidence: ${vulnerability.confidence}`);
    console.log(`Line: ${vulnerability.lineNumber}`);
});
```

## Advanced Configuration

### Custom Vulnerability Patterns

Extend the ML detector with custom patterns:

```csharp
public class CustomMLVulnerabilityProvider : MLVulnerabilityProvider
{
    protected override Dictionary<string, List<VulnerabilityPattern>> InitializeCustomPatterns()
    {
        var patterns = base.InitializeVulnerabilityPatterns();
        
        // Add custom patterns for your organization
        patterns["csharp"].Add(new VulnerabilityPattern
        {
            Id = "CUSTOM-001",
            Name = "Custom Security Rule",
            Regex = new Regex(@"YourCustomPattern"),
            Severity = VulnerabilitySeverity.Medium,
            BaseConfidence = 0.8m,
            Description = "Custom vulnerability detected"
        });
        
        return patterns;
    }
}
```

### Performance Tuning

```json
{
  "AIProviders": {
    "MLVulnerabilityDetector": {
      "MaxCodeLength": 50000,           // Limit analysis size
      "ConfidenceThreshold": 0.5,      // Higher threshold = fewer false positives
      "EnableContextualAnalysis": true, // Enhanced accuracy
      "ParallelProcessing": true        // Faster analysis
    }
  }
}
```

## Testing

### Unit Tests

```csharp
[Fact]
public async Task AnalyzeCode_WithSQLInjection_DetectsVulnerability()
{
    var code = "string sql = \"SELECT * FROM users WHERE id = \" + userId;";
    var result = await mlProvider.AnalyzeCodeAsync(code, context);
    
    Assert.NotEmpty(result.DetectedVulnerabilities);
    Assert.Contains(result.DetectedVulnerabilities, 
        v => v.Type.Contains("SQL Injection"));
}
```

### Integration Tests

```csharp
[Fact]
public async Task HybridProvider_CombinesResults_CorrectEnsembleScoring()
{
    var result = await hybridProvider.AnalyzeCodeAsync(vulnerableCode, context);
    
    Assert.True(result.AnalysisMetadata.ContainsKey("ProvidersUsed"));
    Assert.True((int)result.AnalysisMetadata["ProvidersUsed"] > 1);
}
```

## Monitoring and Metrics

### Key Metrics to Monitor

- **Detection accuracy**: True positive / false positive rates
- **Analysis performance**: Time per line of code analyzed
- **Provider availability**: Health status of external APIs
- **Cost tracking**: Usage costs per analysis

### Health Checks

```csharp
// Check ML provider health
var healthStatus = await mlProvider.GetHealthStatusAsync();
Console.WriteLine($"ML Provider healthy: {healthStatus.IsHealthy}");
Console.WriteLine($"Response time: {healthStatus.ResponseTime}ms");
Console.WriteLine($"Success rate: {healthStatus.SuccessRate:P}");
```

## Troubleshooting

### Common Issues

1. **High false positive rates**
   - Increase `ConfidenceThreshold` in configuration
   - Enable contextual analysis
   - Review custom patterns

2. **Slow analysis performance**
   - Reduce `MaxCodeLength`
   - Enable parallel processing
   - Use local ML provider only

3. **External API failures**
   - Check API key configuration
   - Monitor rate limits
   - Enable fallback to local ML

### Debug Logging

```json
{
  "Logging": {
    "LogLevel": {
      "AISecurityScanner.Infrastructure.AIProviders": "Debug"
    }
  }
}
```

## Security Considerations

- **API keys**: Store securely using Azure Key Vault or similar
- **Data privacy**: Code is not sent to external APIs unless explicitly configured
- **Rate limiting**: Implement appropriate rate limits for external API usage
- **Audit logging**: All detections are logged with timestamps and user context

## Future Enhancements

- **Custom ML model training**: Train models on your organization's codebase
- **Language expansion**: Add support for more programming languages
- **Real-time IDE integration**: VS Code and Visual Studio extensions
- **Advanced reporting**: Trend analysis and compliance reporting